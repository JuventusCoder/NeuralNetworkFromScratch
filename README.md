# Neural Network From Scratch
In this project I have built a simple Neural Network using pure Numpy (no TensorFlow, PyTorch, etc).

## The scope of the project

In this project I have demonstrated the "behind the scenes of a very simple Neural Network (two linear layers with ReLU and Softmax activations).
The purpose of the project is to demonstrate what happens "under the hood" in libraries such as PyTorch or TensorFlow.
I have used the MNIST Digit Recognition Dataset (the simplified 8 by 8 pixels one) as an example.

## What I will further improve.

There are many things you could improve here, but 2 of the most important are:
1) Make the code for backprogation more readable (maybe even introduce autograd).
2) Scale up to the 28 by 28 pixels dataset.

Anyways I find that the project fulfills its goal to build a simple Neural Network without the help of dedicated librries even as it is.

## What you could further do with it.

As I already mentioned, there are many things you can improve in this project, so feel free to download the Notebook and play around with it.
